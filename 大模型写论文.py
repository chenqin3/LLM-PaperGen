# ========= workflow.py =========
import os, sys, json, subprocess, pandas as pd
from datetime import datetime

# ---------- 0. å››å¤§æ¨¡å‹é…ç½® ----------
MODEL_CONFIGS = [
    {  # DeepSeek Reasoner R1
        "name": "deepseek",
        "init": lambda: __import__("openai").OpenAI(
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            base_url="https://api.deepseek.com"
        ),
        "call": lambda cli, sys_msg, usr_msg, temp=None: cli.chat.completions.create(
            model="deepseek-reasoner",
            messages=[{"role":"system","content":sys_msg},
                      {"role":"user","content":usr_msg}]
        ).choices[0].message.content
    },
    {  # o3
        "name": "o3",
        "init": lambda: __import__("openai").OpenAI(api_key=os.getenv("OPENAI_API_KEY")),
        "call": lambda cli, sys_msg, usr_msg, temp=None: cli.chat.completions.create(
            model="o3",
            messages=[{"role":"system","content":sys_msg},
                      {"role":"user","content":usr_msg}],
            response_format={"type":"text"},
            reasoning_effort="medium"
        ).choices[0].message.content
    },
    {  # Gemini 2.5 Pro
        "name": "gemini",
        "init": lambda: __import__("google.genai", fromlist=["Client"]).Client(
            api_key=os.getenv("GEMINI_API_KEY")
        ),
        "call": lambda cli, sys_msg, usr_msg, temp=None: cli.models.generate_content(
            model="gemini-2.5-pro-preview-05-06",
            contents=f"{sys_msg}\n\n{usr_msg}"
        ).text
    },
    {  # Claude-4 Opus
        "name": "claude4",
        "init": lambda: __import__("anthropic").Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY")),
        "call": lambda cli, sys_msg, usr_msg, temp=None: cli.messages.create(
            model="claude-opus-4-20250514",
            max_tokens=4096,
            system=sys_msg,
            messages=[{"role":"user","content":[{"type":"text","text":usr_msg}]}]
        ).content[0].text
    }
]

# ---------- 1. é€šç”¨å·¥å…· ----------
def read_text(path, encodings=('utf-8','gbk','latin1')):
    for enc in encodings:
        try:
            with open(path, encoding=enc) as f:
                return f.read()
        except UnicodeDecodeError:
            continue
    raise UnicodeDecodeError(f"æ— æ³•è¯»å– {path}")

def write_text(path, content):
    with open(path, 'w', encoding='utf-8') as f:
        f.write(content)

def run_py(path):
    try:
        subprocess.check_output([sys.executable, path], stderr=subprocess.STDOUT)
        return True, ""
    except subprocess.CalledProcessError as e:
        return False, e.output.decode('utf-8', errors='ignore')

# æ–°å¢ï¼šæ¸…ç†LLMè¿”å›çš„ä»£ç å­—ç¬¦ä¸²ä¸­çš„Markdownæ ‡è®°
def clean_llm_code_output(code_string):
    if not isinstance(code_string, str):
        return "" 

    lines = code_string.split('\n')

    # å¤´éƒ¨æ¸…ç†ï¼šå¾ªç¯ç§»é™¤å¼€å¤´æ˜¯ç©ºè¡Œæˆ–ä»¥ "```" å¼€å¤´çš„è¡Œ
    while lines:
        stripped_first_line = lines[0].strip()
        if not stripped_first_line or stripped_first_line.startswith("```"):
            lines.pop(0)
        else:
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ‰æ•ˆè¡Œï¼Œåœæ­¢å¤´éƒ¨æ¸…ç†
            break 
    
    # å°¾éƒ¨æ¸…ç†ï¼šå¾ªç¯ç§»é™¤æœ«å°¾æ˜¯ç©ºè¡Œæˆ–ä»¥ "```" å¼€å¤´çš„è¡Œ
    while lines:
        stripped_last_line = lines[-1].strip()
        # åŒæ ·æ£€æŸ¥ç©ºè¡Œæˆ–ä»¥ "```" å¼€å¤´çš„è¡Œ
        if not stripped_last_line or stripped_last_line.startswith("```"):
            lines.pop(-1)
        else:
            # æ‰¾åˆ°æœ€åä¸€ä¸ªæœ‰æ•ˆè¡Œï¼Œåœæ­¢å°¾éƒ¨æ¸…ç†
            break
            
    return '\n'.join(lines).strip()

def fix_code(path, traceback_text, cfg, original_sys_prompt_str, original_user_msg_str, fix_request_system_prompt_str):
    bad_code = read_text(path)

    # æ„å»ºå‘é€ç»™ LLM (ä¿®å¤ä»»åŠ¡) çš„ user_message
    # è¿™ä¸ª user_message æ˜¯ä¸€ä¸ª JSON å­—ç¬¦ä¸²ï¼Œå…¶ç»“æ„ä¸æ–°çš„ step12_fix_code system_prompt ä¸­æè¿°çš„ä¸€è‡´
    user_input_for_fix_task = {
        "original_task_system_prompt": original_sys_prompt_str,
        "original_task_user_input": original_user_msg_str, # original_user_msg_str æœ¬èº«å°±æ˜¯ä¸ªJSONå­—ç¬¦ä¸²
        "erroneous_code": bad_code,
        "traceback": traceback_text
    }
    # å°†åŒ…å«æ‰€æœ‰ä¸Šä¸‹æ–‡çš„å­—å…¸è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²ä½œä¸ºç”¨æˆ·æ¶ˆæ¯
    user_msg_json_for_fix = json.dumps(user_input_for_fix_task, ensure_ascii=False, indent=2)

    cli = cfg["init"]()
    # System prompt ç›´æ¥ä½¿ç”¨ prompts["step12_fix_code"]["content"] (å³ fix_request_system_prompt_str)
    # User message æ˜¯ä¸Šé¢æ„å»ºçš„ JSON å­—ç¬¦ä¸² (user_msg_json_for_fix)
    fixed_raw = cfg["call"](
        cli,
        fix_request_system_prompt_str, 
        user_msg_json_for_fix
    )
    fixed = clean_llm_code_output(fixed_raw)
    write_text(path, fixed)
    return run_py(path)

# ---------- 2. ä¸»æµç¨‹ ----------
def main():
    prompts = json.load(open('prompts.json', 'r', encoding='utf-8'))
    user_topic_input = input("â–¶ è¯·è¾“å…¥ç ”ç©¶ä¸»é¢˜ï¼ˆç•™ç©ºåˆ™è®©æ¨¡å‹è‡ªç”±å‘æŒ¥ï¼‰ï¼š").strip()

    codebook_path, stats_path, struct_path, data_path = (
        "cfps2022codebook.csv", "summ_detail_stats.csv", "å­—æ®µç»“æ„.json", "cfps2022.csv"
    )

    code_df = pd.read_csv(codebook_path, on_bad_lines='skip')
    # name_to_varlab_map: åŸå§‹å­—æ®µå -> å˜é‡çš„ä¸­æ–‡æ ‡ç­¾ (æ¥è‡ªcodebookç¬¬ä¸‰åˆ—varlab)
    name_to_varlab_map = dict(zip(code_df.iloc[:,0], code_df.iloc[:,2]))
    # name_to_vallab_map: åŸå§‹å­—æ®µå -> codebookä¸­çš„vallab (æ¥è‡ªcodebookç¬¬äºŒåˆ—vallab)
    name_to_vallab_map = dict(zip(code_df.iloc[:,0], code_df.iloc[:,1]))

    stats_df = pd.read_csv(stats_path, encoding='utf-8', engine='python')
    struct_json = json.load(open(struct_path, 'r', encoding='utf-8'))
    
    # æŒ‡å®šéœ€è¦çš„ç»Ÿè®¡ç‰¹å¾åˆ—
    STAT_COLUMNS_TO_KEEP = ['mean', 'sd', 'min', 'p1', 'p5', 'p10', 'p25', 'p50', 'p75', 'p90', 'p95', 'p99', 'max', 'skewness', 'kurtosis']

    for cfg in MODEL_CONFIGS:
        print(f"\n\n====================  {cfg['name'].upper()}  ====================\n")
        uid = datetime.now().strftime('%Y%m%d_%H%M%S') + "_" + cfg["name"]

        # ---------- STEP 1: Topic and Fields ----------
        # å‘é€ç»™LLMçš„codebookæŠ½æ ·ä»…åŒ…å«ç¬¬ä¸€åˆ—(name)å’Œç¬¬ä¸‰åˆ—(varlab)
        cb_sample_df = pd.read_csv(codebook_path, usecols=[0, 2], on_bad_lines='skip')
        cb_sample_csv_string = cb_sample_df.to_csv(index=False)
        
        step1_user_msg = json.dumps(
            {"codebook_sample": cb_sample_csv_string, "user_topic": user_topic_input},
            ensure_ascii=False
        )
        cli = cfg["init"]()
        step1_raw = cfg["call"](
            cli,
            prompts["step1_topic_and_fields"]["content"],
            step1_user_msg
        )
        print("Step 1  è¾“å‡ºï¼š\\n", step1_raw, "\\n")
        cleaned_step1_raw = clean_llm_code_output(step1_raw) 


        s1 = json.loads(cleaned_step1_raw) 
        topic, need_fields = s1["topic"], s1["needed_fields"] # need_fieldsæ˜¯åŸå§‹å­—æ®µååˆ—è¡¨
        print("â–¶  ç ”ç©¶ä¸»é¢˜ï¼š", topic)
        print("â–¶  é¦–è½®å­—æ®µï¼š", need_fields, "\n")

        # ---------- Function to build meta structure for fields ----------
        def build_fields_meta(field_names_list, codebook_df, stats_df, struct_json, name_to_varlab_map, name_to_vallab_map, stat_columns):
            meta_list = []
            # Asegurar que stats_df tenga 'variable' como Ã­ndice para bÃºsqueda eficiente
            if 'variable' not in stats_df.columns:
                print("é”™è¯¯ï¼šsumm_detail_stats.csv æ–‡ä»¶ç¼ºå°‘ 'variable' åˆ—")
                return [] # O manejar el error como se prefiera
                
            stats_df_indexed = stats_df.set_index('variable', drop=False) # drop=False para mantener la columna
            
            for field_name in field_names_list:
                var_label = name_to_varlab_map.get(field_name, "") # ä¸­æ–‡æ ‡ç­¾
                vallab_from_codebook = name_to_vallab_map.get(field_name, None) # ä»codebookè·å–vallab
                
                value_meanings = {}
                if vallab_from_codebook:
                    value_meanings = struct_json.get(vallab_from_codebook, {}) # ç”¨vallabå»å­—æ®µç»“æ„JSONæŸ¥æ‰¾
                else:
                    # Fallback si no se encuentra vallab, intentar con field_name (aunque la lÃ³gica solicitada es via vallab)
                    value_meanings = struct_json.get(field_name, {}) 

                field_stats_data = {}
                if field_name in stats_df_indexed.index:
                    stats_series = stats_df_indexed.loc[field_name]
                    # Filtrar solo las columnas de estadÃ­sticas deseadas y manejar NaNs
                    field_stats_data = {col: stats_series.get(col) for col in stat_columns if pd.notna(stats_series.get(col))}
                
                meta_list.append({
                    "var": field_name, # åŸå§‹å­—æ®µå
                    "label": var_label, # å­—æ®µä¸­æ–‡æ ‡ç­¾ (æ¥è‡ªcodebookçš„varlab)
                    "value_map": value_meanings, # å€¼å¯¹åº”çš„å«ä¹‰ (é€šè¿‡name -> codebook.vallab -> struct.json)
                    "stats": field_stats_data # æŒ‡å®šçš„ç»Ÿè®¡ç‰¹å¾
                })
            return meta_list

        # ---------- STEP 2 & 3: Study Plan (using new meta structure) ----------
        meta_for_study_plan = build_fields_meta(need_fields, code_df, stats_df, struct_json, name_to_varlab_map, name_to_vallab_map, STAT_COLUMNS_TO_KEEP)
        
        step3_input_data = {"topic": topic, "fields_meta": meta_for_study_plan}
        step3_user_msg = json.dumps(step3_input_data, ensure_ascii=False, sort_keys=True, indent=2) # indent for debug
        
        cli = cfg["init"]()
        step3_raw = cfg["call"](
            cli, prompts["step3_study_plan"]["content"], step3_user_msg
        )
        print("Step 3  è¾“å‡ºï¼š\\n", step3_raw, "\\n")
        cleaned_step3_raw = clean_llm_code_output(step3_raw) 

        s3 = json.loads(cleaned_step3_raw) 
        plan, filt_fields = s3["plan"], s3["filtered_fields"] # filt_fieldsæ˜¯åŸå§‹å­—æ®µååˆ—è¡¨
        print("â–¶  æœ€ç»ˆå­—æ®µï¼š", filt_fields, "\n")

        # ---------- STEP 4 & 5 & 7: Code Generation (using new meta2 structure) ----------
        meta2_for_code_gen = build_fields_meta(filt_fields, code_df, stats_df, struct_json, name_to_varlab_map, name_to_vallab_map, STAT_COLUMNS_TO_KEEP)

        # STEP 5: Generate Plot Code
        step5_input_data = {"plan": plan, "fields_meta": meta2_for_code_gen}
        step5_user_msg = json.dumps(step5_input_data, ensure_ascii=False, sort_keys=True, indent=2)
        
        cli = cfg["init"]()
        plot_code_raw = cfg["call"](cli, prompts["step5_generate_plot_code"]["content"], step5_user_msg)
        print("Step 5  ç”Ÿæˆç»˜å›¾ä»£ç ï¼š\\n", plot_code_raw[:400], "...\\n")
        plot_code = clean_llm_code_output(plot_code_raw)

        plot_py = f"plot_{uid}.py"
        write_text(plot_py, plot_code)

        # Initial run for plot script
        ok, run_err = run_py(plot_py)

        if not ok:  # Initial run failed
            print(f"ç»˜å›¾è„šæœ¬ {plot_py} åˆæ¬¡è¿è¡Œå‡ºé”™ï¼Œé”™è¯¯: {str(run_err)[:200]}... å°è¯•ç¬¬ä¸€æ¬¡è‡ªåŠ¨ä¿®å¤â€¦")
            # First fix attempt for plot script
            ok, fix1_run_err = fix_code(
                plot_py,
                str(run_err),  # Error from initial run
                cfg,
                prompts["step5_generate_plot_code"]["content"],
                step5_user_msg,
                prompts["step12_fix_code"]["content"]
            )

            if not ok:  # First fix attempt failed
                print(f"ç»˜å›¾è„šæœ¬ {plot_py} ç¬¬ä¸€æ¬¡ä¿®å¤åè¿è¡Œä»å‡ºé”™ï¼Œé”™è¯¯: {str(fix1_run_err)[:200]}... å°è¯•ç¬¬äºŒæ¬¡è‡ªåŠ¨ä¿®å¤â€¦")
                # Second fix attempt for plot script
                ok, fix2_run_err = fix_code(
                    plot_py,
                    str(fix1_run_err),  # Error from run after first fix
                    cfg,
                    prompts["step5_generate_plot_code"]["content"],
                    step5_user_msg,
                    prompts["step12_fix_code"]["content"]
                )
                if not ok:  # Second fix attempt also failed
                    print(f"è­¦å‘Š: {plot_py} ä¸¤æ¬¡è‡ªåŠ¨ä¿®å¤åä»æ‰§è¡Œå¤±è´¥ã€‚æœ€åé”™è¯¯ä¿¡æ¯: {str(fix2_run_err)}")
        
        # Handle plot.png generation
        if os.path.exists("plot.png"):
            os.rename("plot.png", f"plot_{uid}.png")
        else:
            if ok:  # if script overall status is OK (initial or after fixes)
                print(f"æ³¨æ„: {plot_py} æ‰§è¡ŒæˆåŠŸä½†æœªç”Ÿæˆ plot.png æ–‡ä»¶ã€‚")
            # If not ok, the warning about failed fixes (after 2 attempts) has already been printed.

        # STEP 7: Generate Regression Code
        step7_input_data = {"plan": plan, "fields_meta": meta2_for_code_gen}
        step7_user_msg = json.dumps(step7_input_data, ensure_ascii=False, sort_keys=True, indent=2)
        
        cli = cfg["init"]()
        reg_code_raw = cfg["call"](cli, prompts["step7_generate_reg_code"]["content"], step7_user_msg)
        print("Step 7  ç”Ÿæˆå›å½’ä»£ç ï¼š\\n", reg_code_raw[:400], "...\\n")
        reg_code = clean_llm_code_output(reg_code_raw)

        reg_py = f"reg_{uid}.py"
        write_text(reg_py, reg_code)

        # Initial run for regression script
        ok, run_err = run_py(reg_py)

        if not ok:  # Initial run failed
            print(f"å›å½’è„šæœ¬ {reg_py} åˆæ¬¡è¿è¡Œå‡ºé”™ï¼Œé”™è¯¯: {str(run_err)[:200]}... å°è¯•ç¬¬ä¸€æ¬¡è‡ªåŠ¨ä¿®å¤â€¦")
            # First fix attempt for regression script
            ok, fix1_run_err = fix_code(
                reg_py,
                str(run_err),  # Error from initial run
                cfg,
                prompts["step7_generate_reg_code"]["content"],
                step7_user_msg,
                prompts["step12_fix_code"]["content"]
            )

            if not ok:  # First fix attempt failed
                print(f"å›å½’è„šæœ¬ {reg_py} ç¬¬ä¸€æ¬¡ä¿®å¤åè¿è¡Œä»å‡ºé”™ï¼Œé”™è¯¯: {str(fix1_run_err)[:200]}... å°è¯•ç¬¬äºŒæ¬¡è‡ªåŠ¨ä¿®å¤â€¦")
                # Second fix attempt for regression script
                ok, fix2_run_err = fix_code(
                    reg_py,
                    str(fix1_run_err),  # Error from run after first fix
                    cfg,
                    prompts["step7_generate_reg_code"]["content"],
                    step7_user_msg,
                    prompts["step12_fix_code"]["content"]
                )
                if not ok:  # Second fix attempt also failed
                    print(f"è­¦å‘Š: {reg_py} ä¸¤æ¬¡è‡ªåŠ¨ä¿®å¤åä»æ‰§è¡Œå¤±è´¥ã€‚æœ€åé”™è¯¯ä¿¡æ¯: {str(fix2_run_err)}")

        # Handle result.txt generation
        if os.path.exists("result.txt"):
            os.rename("result.txt", f"result_{uid}.txt")
        else:
            if ok:  # if script overall status is OK (initial or after fixes)
                 print(f"æ³¨æ„: {reg_py} æ‰§è¡ŒæˆåŠŸä½†æœªç”Ÿæˆ result.txt æ–‡ä»¶ã€‚")
            # If not ok, the warning about failed fixes (after 2 attempts) has already been printed.

        # ---------- STEP 9: Result Analysis ----------
        result_txt_path = f"result_{uid}.txt"
        if not os.path.exists(result_txt_path):
            print(f"è­¦å‘Š: å›å½’ç»“æœæ–‡ä»¶ {result_txt_path} æœªæ‰¾åˆ°ï¼Œè·³è¿‡ç»“æœåˆ†æå’Œåç»­æ­¥éª¤ã€‚")
            analysis = "å›å½’ç»“æœæ–‡ä»¶æœªç”Ÿæˆï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚"
            abstract = "ç”±äºå›å½’ç»“æœç¼ºå¤±ï¼Œæ— æ³•ç”Ÿæˆæ‘˜è¦ã€‚"
        else:
            result_txt = read_text(result_txt_path)
            step9_input_data = {"plan":plan,"fields_meta":meta2_for_code_gen,"results":result_txt}
            step9_user_msg = json.dumps(step9_input_data, ensure_ascii=False, sort_keys=True, indent=2)
            cli = cfg["init"]()
            analysis = cfg["call"](cli, prompts["step9_result_analysis"]["content"], step9_user_msg)
            print("Step 9  ç»“æœåˆ†æï¼š\n", analysis, "\n")
            write_text(f"analysis_{uid}.txt", analysis)

            # ---------- STEP 10: Abstract ----------
            cli = cfg["init"]()
            abstract = cfg["call"](cli, prompts["step10_abstract_and_intro"]["content"], analysis)
            print("Step 10  æ‘˜è¦ï¼š\n", abstract, "\n")
            write_text(f"abstract_{uid}.txt", abstract)

        # ---------- STEP 11: Assemble Markdown Document ----------
        md_content = []
        md_content.append(f"# {topic}\n")
        md_content.append(f"{abstract}\n")
        md_content.append("--- \n") # Page break representation or separator

        md_content.append("## ç ”ç©¶è®¡åˆ’\n")
        md_content.append(f"{plan}\n")

        plot_image_path = f"plot_{uid}.png"
        if os.path.exists(plot_image_path):
            # Using relative path for the image in Markdown
            md_content.append(f"![Plot](./{os.path.basename(plot_image_path)})\n")
        else:
            md_content.append(f"[å›¾ç‰‡ {plot_image_path} æœªç”Ÿæˆ]\n")

        md_content.append("\n## å›å½’ç»“æœ\n")
        # result_txt_path was defined in STEP 7/9
        if os.path.exists(result_txt_path):
            # Wrap .txt content in a text code block to preserve formatting
            md_content.append(f"```text\n{read_text(result_txt_path)}\n```\n")
        else:
            md_content.append("[å›å½’ç»“æœæ–‡ä»¶æœªç”Ÿæˆ]\n")
            
        md_content.append("\n## ç»“æœè§£è¯»\n")
        # analysis_file_path was defined in STEP 9
        if os.path.exists(f"analysis_{uid}.txt"):
            md_content.append(f"{read_text(f'analysis_{uid}.txt')}\n")
        else:
             md_content.append("[ç»“æœè§£è¯»æ–‡ä»¶æœªç”Ÿæˆ]\n")
        
        output_md_filename = f"paper_{uid}.md"
        write_text(output_md_filename, "\n".join(md_content))
        print(f"ğŸ‰  å®Œæˆï¼š{output_md_filename}\n")

if __name__ == "__main__":
    main()
